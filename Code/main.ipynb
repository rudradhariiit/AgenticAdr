{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LAB\\ADR\\AgenticAdr\n"
     ]
    }
   ],
   "source": [
    "cd D:\\LAB\\ADR\\AgenticAdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a47523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.AdrAgents import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72638812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adrs(repo_url_to_process):\n",
    "    output_directory_for_adrs = 'Generated_ADRs/' + repo_url_to_process[19:].removesuffix('.git').replace('/', '_')\n",
    "\n",
    "    output_directory_for_adrs_gimini = output_directory_for_adrs + '/dir3'\n",
    "    model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gimini = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gimini.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gimini,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gimini. {len(final_adrs)} ADRs were generated and saved.\")\n",
    "\n",
    "    output_directory_for_adrs_gpt = output_directory_for_adrs + '/dir4'\n",
    "    model_name = \"gpt-5\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gpt = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gpt.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gpt,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gpt. {len(final_adrs)} ADRs were generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f529e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sambuaneesh/why-py into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpra32x2ct...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: parser.py\n",
      "  - Reading: documentation\\public\\interpreter\\parser.py\n",
      "  - Reading: parser_test.py\n",
      "  - Reading: documentation\\src\\styles\\custom.css\n",
      "  - Reading: eval_test.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpra32x2ct...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repository's structure, correctly identifying the dual nature of the project: a Python-based interpreter in the root directory and an Astro-based documentation website in the `documentation/` subdirectory. It correctly points to key files and components like `lexer.py`, `parser.py`, `eval.py`, the `*_test.py` suite, `InteractiveRepl.jsx`, and `copy-interpreter.js`, and accurately infers their roles within the project's architecture.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 7 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a comprehensive and accurate reflection of the key architectural decisions outlined in the Repository Summary. Each ADR is directly supported by specific details in the summary, covering the interpreter's classic pattern (ADR-001), the choice of a Pratt parser (ADR-002), the documentation's tech stack (ADR-003, ADR-004), the overall project structure (ADR-005), the core language design (ADR-006), and the testing strategy (ADR-007). The context and consequences for each decision are plausible and well-articulated.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sambuaneesh_why-py\\dir3'\n",
      "  -> Successfully saved 001_Classic_Interpreter_Architectural_Pattern.md\n",
      "  -> Successfully saved 002_Adoption_of_a_Pratt_Parser.md\n",
      "  -> Successfully saved 003_Static_Site_Generation_for_Documentation.md\n",
      "  -> Successfully saved 004_Integration_of_an_Interactive_In-Browser_REPL.md\n",
      "  -> Successfully saved 005_Architectural_Decoupling_of_Interpreter_and_Website.md\n",
      "  -> Successfully saved 006_Thematic_and_Esoteric_Language_Design.md\n",
      "  -> Successfully saved 007_Comprehensive_Unit_Testing_for_Core_Logic.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 7 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sambuaneesh/why-py into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpodt8jd18...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: parser.py\n",
      "  - Reading: documentation\\public\\interpreter\\parser.py\n",
      "  - Reading: parser_test.py\n",
      "  - Reading: documentation\\src\\styles\\custom.css\n",
      "  - Reading: eval_test.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpodt8jd18...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts many specifics that arenâ€™t verifiable from the provided file tree (e.g., exact keywords like â€œmanifest,â€ â€œwhenceâ€¦unfoldâ€¦fold,â€ â€œseal,â€ operator names, presence of strings, and Starlight/theming details). \n",
      "\n",
      "FEEDBACK: Revise the summary to stick to facts evident from the repository structure:\n",
      "- Confirm itâ€™s a Python interpreter with lexer, parser, AST, evaluator, environment, and object model, plus tests, REPL, and a docs site that mirrors the interpreter under documentation/public/interpreter and uses copy-interpreter.js.\n",
      "- Avoid naming specific language keywords/operators or parser style (Pratt) unless verified from source/tests.\n",
      "- Avoid unverified claims about documentation framework features (e.g., Starlight, theming) and runtime types (e.g., strings, functions) unless confirmed by the code.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: parser.py\n",
      "  - Reading: documentation\\public\\interpreter\\parser.py\n",
      "  - Reading: parser_test.py\n",
      "  - Reading: documentation\\src\\styles\\custom.css\n",
      "  - Reading: eval_test.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpodt8jd18...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repositoryâ€™s Python interpreter, its tests, REPL, documentation site (with Astro tooling), mirrored interpreter files under documentation/public/interpreter maintained by copy-interpreter.js, and supporting materials like the Makefile and report files.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary and capture the key decisions: a layered interpreter design, hand-written lexer/parser, AST as IR, tree-walking evaluation, dedicated runtime objects and environments, unit testing with unittest, REPL/CLI entry points, an Astro/React documentation site with mirrored source via a sync script, and Makefile-based workflows. The contexts, decisions, and consequences are plausible and consistent with the described codebase and tooling.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sambuaneesh_why-py\\dir4'\n",
      "  -> Successfully saved 001_Layered_interpreter_architecture.md\n",
      "  -> Successfully saved 002_Hand-written_lexer_and_parser.md\n",
      "  -> Successfully saved 003_AST_as_canonical_intermediate_representation.md\n",
      "  -> Successfully saved 004_Tree-walking_evaluator_over_VMbytecode.md\n",
      "  -> Successfully saved 005_Dedicated_runtime_object_model.md\n",
      "  -> Successfully saved 006_Lexically_scoped_environment_with_nested_bindings.md\n",
      "  -> Successfully saved 007_Comprehensive_stage-wise_unit_testing.md\n",
      "  -> Successfully saved 008_Interactive_REPL_and_CLI_entry_points.md\n",
      "  -> Successfully saved 009_Documentation_site_built_with_Astro_and_React.md\n",
      "  -> Successfully saved 010_Mirrored_interpreter_source_in_documentation.md\n",
      "  -> Successfully saved 011_Makefile-driven_developer_workflows.md\n",
      "  -> Successfully saved 012_Docs_structure_mirrors_interpreter_internals_and_language_guide.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/montycloud/moya into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpf40r7282...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: docs\\reference.md\n",
      "  - Reading: moya\\agents\\openai_agent.py\n",
      "  - Reading: examples\\quick_start_multiagent_react.py\n",
      "  - Reading: examples\\dynamic_agents.py\n",
      "  - Reading: moya\\agents\\agent.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpf40r7282...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repository's structure, correctly identifying its core components (Agents, Orchestrators, Tools, Memory), their specific implementations, and key features like multi-provider support and dynamic agent management, all of which are directly verifiable from the file and directory list.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a flawless representation of the key architectural decisions outlined in the Repository Summary. Each ADR directly corresponds to a major component or design philosophy described in the summary, including the provider-agnostic agent abstraction, pluggable orchestrators, the repository pattern for persistence, the tool abstraction layer, dynamic agent management, and the overall modular, component-based design. The context, decision, and consequences for each ADR are logical and well-supported by the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\montycloud_moya\\dir3'\n",
      "  -> Successfully saved 001_Provider-Agnostic_Agent_Abstraction.md\n",
      "  -> Successfully saved 002_Pluggable_Orchestration_Strategies.md\n",
      "  -> Successfully saved 003_Decoupled_Persistence_Layer_via_Repository_Pattern.md\n",
      "  -> Successfully saved 004_Formalized_Tool_Abstraction_Layer.md\n",
      "  -> Successfully saved 005_Dynamic_Runtime_Agent_Management_and_Routing.md\n",
      "  -> Successfully saved 006_Modular_Component-Based_Core_Architecture.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/montycloud/moya into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp_osaul1i...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: docs\\reference.md\n",
      "  - Reading: moya\\agents\\openai_agent.py\n",
      "  - Reading: examples\\quick_start_multiagent_react.py\n",
      "  - Reading: examples\\dynamic_agents.py\n",
      "  - Reading: moya\\agents\\agent.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp_osaul1i...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary aligns well with the repository structure and components, accurately covering agents (OpenAI, Azure, Bedrock, Ollama, CrewAI, Remote), tools (including EphemeralMemory), orchestrators (simple, ReAct, multi-agent), classifiers, conversation primitives, memory repositories, registries, documentation, and examples. Minor speculative details (e.g., streaming, specific config dataclasses) do not detract from the overall accuracy.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 15 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align closely with the repository summary and cover the key architectural decisions: layered separation (agents/orchestrators/tools/memory/conversation/registries), abstract Agent with provider-specific implementations, tool system with JSON schemas and registry, iteration limits for tool loops, classifier-driven routing, ReAct support, conversation primitives, pluggable memory (including EphemeralMemory), centralized registries, multi-backend and remote agents, optional streaming, dataclass-based config, governance via classifier prompts/catalogs, security guidance, and observability hooks. The Context, Decision, and Consequences are plausible and directly supported by the summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\montycloud_moya\\dir4'\n",
      "  -> Successfully saved 001_Layered_modular_architecture_separating_Agents_Orchestrators_Tools_Memory_Conversation_and_Registrie.md\n",
      "  -> Successfully saved 002_Abstract_Agent_interface_with_provider-specific_implementations.md\n",
      "  -> Successfully saved 003_Function-calling_tool_system_with_JSON_schemas_and_a_ToolRegistry.md\n",
      "  -> Successfully saved 004_Controlled_tool_invocation_with_iteration_limits.md\n",
      "  -> Successfully saved 005_Classifier-driven_routing_in_orchestrators_rather_than_agents.md\n",
      "  -> Successfully saved 006_First-class_ReAct-style_reasoning_and_acting.md\n",
      "  -> Successfully saved 007_Conversation_primitives_for_role-structured_history.md\n",
      "  -> Successfully saved 008_Pluggable_memory_repositories_with_an_EphemeralMemory_tool.md\n",
      "  -> Successfully saved 009_Centralized_registries_for_agents_and_tools_enabling_dynamic_composition.md\n",
      "  -> Successfully saved 010_Multi-backend_support_including_remote_agents.md\n",
      "  -> Successfully saved 011_Optional_streaming_support_for_latency-sensitive_responses.md\n",
      "  -> Successfully saved 012_Dataclass-based_configuration_and_default_parameter_merging.md\n",
      "  -> Successfully saved 013_LLM-in-the-loop_governance_via_prompts_and_catalogs.md\n",
      "  -> Successfully saved 014_Security_and_safety_by_design_for_tool_execution.md\n",
      "  -> Successfully saved 015_Observability_delegated_to_integrators_with_suggested_hooks.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 15 ADRs were generated and saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Repository URL\n",
    "https://github.com/karthikv1392/cs6401_se.git\"\n",
    "https://github.com/sa4s-serc/HarmonE\n",
    "https://github.com/srini1978/carbonQL\n",
    "https://github.com/srini1978/AzureCognitiveSearchDemo\n",
    "https://github.com/likhithkanigolla/LLMOps-Platform\n",
    "https://github.com/likhithkanigolla/CAPS-IIITH\n",
    "https://github.com/sa4s-serc/EdgeMLBalancer\n",
    "https://github.com/sa4s-serc/switch\n",
    "https://github.com/sa4s-serc/EcoMLS\n",
    "https://github.com/sa4s-serc/AdaMLS\n",
    "https://github.com/akhiha/juice-shop\n",
    "https://gitlab.com/20a_akhila/amazon-clone\n",
    "https://gitlab.com/20a_akhila/movie-database\n",
    "https://gitlab.com/20a_akhila/silly_story_generator\n",
    "https://github.com/sambuaneesh/why-py\n",
    "https://github.com/montycloud/moya\n",
    "\"\"\"\n",
    "\n",
    "repos = [\"https://github.com/sambuaneesh/why-py\",\n",
    "         \"https://github.com/montycloud/moya\"]\n",
    "\n",
    "for repo_url_to_process in repos:\n",
    "    generate_adrs(repo_url_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c18234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
