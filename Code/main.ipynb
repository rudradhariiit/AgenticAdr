{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LAB\\ADR\\AgenticAdr\n"
     ]
    }
   ],
   "source": [
    "cd D:\\LAB\\ADR\\AgenticAdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a47523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.AdrAgents import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72638812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adrs(repo_url_to_process):\n",
    "    output_directory_for_adrs = 'Generated_ADRs/' + repo_url_to_process[19:].removesuffix('.git').replace('/', '_')\n",
    "\n",
    "    output_directory_for_adrs_gimini = output_directory_for_adrs + '/dir3'\n",
    "    model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gimini = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gimini.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gimini,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gimini. {len(final_adrs)} ADRs were generated and saved.\")\n",
    "\n",
    "    output_directory_for_adrs_gpt = output_directory_for_adrs + '/dir4'\n",
    "    model_name = \"gpt-5\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gpt = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gpt.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gpt,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gpt. {len(final_adrs)} ADRs were generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/srini1978/carbonQL.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpilh3r81p...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: carbonQLConsole\\obj\\carbonQLConsole.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLConsole\\obj\\project.assets.json\n",
      "  - Reading: carbonQLBackend\\obj\\carbonQLBackend.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLBackend\\obj\\project.assets.json\n",
      "  - Reading: carbonQLConsole\\obj\\Debug\\net7.0\\carbonQLConsole.csproj.FileListAbsolute.txt\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpilh3r81p...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repository's structure, technology stack, and architectural design. It correctly identifies the two distinct projects (`carbonQLBackend` as a logic library and `carbonQLConsole` as a consumer), the use of .NET 7.0, and the presence of a GitHub Actions workflow. All inferences about the project's purpose and design are well-supported by the file names and directory layout.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 4 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs accurately capture and are directly supported by all the key architectural decisions highlighted in the Repository Summary. The ADRs correctly document the n-tier architecture (ADR-001), the choice of the .NET 7.0 framework (ADR-002), the MVC-inspired internal structure of the backend (ADR-003), and the establishment of a CI pipeline with GitHub Actions (ADR-004). All points are consistent with the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\srini1978_carbonQL\\dir3'\n",
      "  -> Successfully saved 001_N-Tier_Architecture_with_Decoupled_Core_Logic.md\n",
      "  -> Successfully saved 002_Adoption_of_.NET_7.0_Framework.md\n",
      "  -> Successfully saved 003_MVC-Inspired_Pattern_for_Backend_Organization.md\n",
      "  -> Successfully saved 004_Establishment_of_a_Foundational_CI_Pipeline.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 4 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/srini1978/carbonQL.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpobj9t1ln...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: carbonQLConsole\\obj\\carbonQLConsole.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLConsole\\obj\\project.assets.json\n",
      "  - Reading: carbonQLBackend\\obj\\carbonQLBackend.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLBackend\\obj\\project.assets.json\n",
      "  - Reading: carbonQLConsole\\obj\\Debug\\net7.0\\carbonQLConsole.csproj.FileListAbsolute.txt\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpobj9t1ln...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes speculative build/restore details (e.g., NU1605 warn-as-error, Runtime Identifier graph usage, assets manifest version) that are not evidenced in the provided files.\n",
      "\n",
      "FEEDBACK: \n",
      "- Remove unverified claims about NuGet restore settings (NU1605, RID graph) and asset manifest versioning.\n",
      "- State simply that there are no external NuGet package dependencies; only the .NET 7 framework is referenced.\n",
      "- Rephrase CI/CD to note that a GitHub Actions workflow file (dotnet-desktop.yml) exists, without asserting specific steps unless you inspect its contents.\n",
      "- Keep the accurate parts: two-project .NET 7 solution (class library with Model/Controller folders and a console app), outputs in bin/obj, and the console consuming the backend library.\n",
      "- Optional: Mention the presence of README.md and lack of tests observed.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: carbonQLConsole\\obj\\carbonQLConsole.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLConsole\\obj\\project.assets.json\n",
      "  - Reading: carbonQLBackend\\obj\\carbonQLBackend.csproj.nuget.dgspec.json\n",
      "  - Reading: carbonQLBackend\\obj\\project.assets.json\n",
      "  - Reading: carbonQLConsole\\obj\\Debug\\net7.0\\carbonQLConsole.csproj.FileListAbsolute.txt\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpobj9t1ln...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the .NET 7 solution with a backend class library (Model/Controller) and a console app consuming it, correctly notes build artifacts, lack of external NuGet packages, presence of the workflow and README, and the minimal layered architecture.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary: .NET 7 targeting, a two-project solution with a reusable backend library, a Model/Controller layering, console app entry point, project-to-project reference, no external NuGet packages, no tests, presence of a GitHub Actions workflow, framework-dependent builds, and the absence of configuration/DI/logging/persistence are all directly supported. The contexts, decisions, and consequences are plausible for a small .NET 7 console + library setup.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\srini1978_carbonQL\\dir4'\n",
      "  -> Successfully saved 001_Platform_choice_.NET_7_STS_for_all_projects.md\n",
      "  -> Successfully saved 002_Two-project_solution_with_reusable_backend_library.md\n",
      "  -> Successfully saved 003_Layered_structure_Model_and_Controller.md\n",
      "  -> Successfully saved 004_Console_application_as_the_entry_point.md\n",
      "  -> Successfully saved 005_Project-to-project_reference_for_library_consumption.md\n",
      "  -> Successfully saved 006_No_external_NuGet_dependencies.md\n",
      "  -> Successfully saved 007_Absence_of_automated_tests.md\n",
      "  -> Successfully saved 008_Basic_CI_via_GitHub_Actions_workflow.md\n",
      "  -> Successfully saved 009_Framework-dependent_deployment.md\n",
      "  -> Successfully saved 010_No_explicit_configuration_management.md\n",
      "  -> Successfully saved 011_No_dependency_injection_logging_or_telemetry_infrastructure.md\n",
      "  -> Successfully saved 012_No_persistence_or_external_integration_layer.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/srini1978/AzureCognitiveSearchDemo.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzzsv_2w0...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: sampledocs\\10-K-FY16.html\n",
      "  - Reading: Customskills\\BingCustomSearch.cs\n",
      "  - Reading: sampledocs\\satyasletter.txt\n",
      "  - Reading: README.md\n",
      "  - Reading: Customskills\\local.settings.json\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzzsv_2w0...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately deduces the project's architecture and purpose from the provided file structure. The presence of `Customskills/BingCustomSearch.cs` and Azure Function configuration files (`host.json`, `local.settings.json`) strongly supports the description of an AI enrichment pipeline using a .NET custom skill to call the Bing Search API. The `sampledocs/` directory confirms the diverse data source, and the overall description of an Azure Cognitive Search solution is a logical and correct interpretation of these components.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 5 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are excellent and accurately reflect the key architectural decisions outlined in the repository summary. They logically separate the major choicesâ€”the managed search platform (ADR-001), the custom enrichment pattern (ADR-002), the data source (ADR-003), the implementation language (ADR-004), and the external data dependency (ADR-005)â€”into distinct, well-reasoned records. Each ADR's context, decision, and consequences are fully supported by the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\srini1978_AzureCognitiveSearchDemo\\dir3'\n",
      "  -> Successfully saved 001_Adoption_of_a_Managed_Search_Service_for_the_Core_Architecture.md\n",
      "  -> Successfully saved 002_Extensible_Data_Enrichment_via_Serverless_Custom_Skills.md\n",
      "  -> Successfully saved 003_Unstructured_Data_Sourcing_via_Cloud_Blob_Storage.md\n",
      "  -> Successfully saved 004_Selection_of_.NET_for_Serverless_Function_Implementation.md\n",
      "  -> Successfully saved 005_Leveraging_an_External_API_for_Real-time_Data_Augmentation.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 5 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/srini1978/AzureCognitiveSearchDemo.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpc19nia6o...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: sampledocs\\10-K-FY16.html\n",
      "  - Reading: Customskills\\BingCustomSearch.cs\n",
      "  - Reading: sampledocs\\satyasletter.txt\n",
      "  - Reading: README.md\n",
      "  - Reading: Customskills\\local.settings.json\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpc19nia6o...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts specifics that arenâ€™t supported by the provided repository context (which only lists files/directories, not file contents).\n",
      "\n",
      "FEEDBACK: Revise the summary to stick to whatâ€™s evidenced by the file structure:\n",
      "- State that itâ€™s a C# Azure Functions project (Customskills folder with .csproj, host.json, local.settings.json) containing a BingCustomSearch.cs likely related to a custom skill.\n",
      "- Describe sampledocs as a local set of mixed-format documents; donâ€™t claim Blob Storage usage or README walkthroughs unless confirmed from README content.\n",
      "- Avoid asserting the Function is HTTP-triggered, its exact input/output fields, or that local.settings.json has specific values (e.g., empty AzureWebJobsStorage, configured worker runtime) without verification.\n",
      "- Keep high-level notes about potential use with Azure Cognitive Search and custom skills, and accurately note that no skillset/index/indexer JSON definitions are present.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: sampledocs\\10-K-FY16.html\n",
      "  - Reading: Customskills\\BingCustomSearch.cs\n",
      "  - Reading: sampledocs\\satyasletter.txt\n",
      "  - Reading: README.md\n",
      "  - Reading: Customskills\\local.settings.json\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpc19nia6o...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts specific contents of the README (workflow details about indexing/querying, Blob Storage, Search Explorer) that are not verifiable from the provided repository structure alone.\n",
      "FEEDBACK: Remove or soften any claims about the READMEâ€™s content unless you cite explicit lines. Rephrase to: â€œREADME.md is present; its contents are not shown here.â€ Keep the rest as observations or clearly labeled inferences (e.g., â€œappears to be an Azure Functions project,â€ â€œlikely intended for a custom skill with Bing Custom Searchâ€).\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 3 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: sampledocs\\10-K-FY16.html\n",
      "  - Reading: Customskills\\BingCustomSearch.cs\n",
      "  - Reading: sampledocs\\satyasletter.txt\n",
      "  - Reading: README.md\n",
      "  - Reading: Customskills\\local.settings.json\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpc19nia6o...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes speculative details not supported by the provided file listing.\n",
      "FEEDBACK: Revise the summary to avoid unverified specifics. Do not claim hardcoded credentials, specific HTTP trigger shape, input/output schemas (e.g., â€œrecords,â€ DataEntities, fields like snippet/last crawled), or the exact contents of local.settings.json. Instead, state that:\n",
      "- The Customskills folder contains a C# Azure Functions-style project (indicated by .csproj, host.json, local.settings.json) with a BingCustomSearch.cs file that likely integrates Bing Custom Search as a custom skill for Azure Cognitive Search.\n",
      "- Configuration details and function behavior are not confirmed without code/README content.\n",
      "- sampledocs contains mixed-format sample files likely for indexing/enrichment demos.\n",
      "Keep recommendations high level (e.g., externalizing config) without asserting that secrets are hardcoded.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 10 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary, covering the key decisions: using .NET Azure Functions as a custom skill, wrapping Bing Custom Search, adhering to the Cognitive Search records contract via HTTP POST, structured result normalization, secrets/config handling, Functions runtime/storage dependencies, per-record API calls, absence of IaC, and inclusion of heterogeneous sample docs. The Context, Decision, and Consequences sections are consistent and plausible for this project.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\srini1978_AzureCognitiveSearchDemo\\dir4'\n",
      "  -> Successfully saved 001_Azure_Function_as_Cognitive_Search_Custom_Skill.md\n",
      "  -> Successfully saved 002_Use_Bing_Custom_Search_for_External_Enrichment.md\n",
      "  -> Successfully saved 003_HTTP-triggered_Function_Implementing_the_Cognitive_Search_Records_Contract.md\n",
      "  -> Successfully saved 004_Structured_Output_Schema_for_Search_Results.md\n",
      "  -> Successfully saved 005_Configuration_and_Secrets_Handling.md\n",
      "  -> Successfully saved 006_.NET_Azure_Functions_Runtime_Selection.md\n",
      "  -> Successfully saved 007_AzureWebJobsStorage_Dependency_for_Function_Host.md\n",
      "  -> Successfully saved 008_Per-record_Invocation_of_External_Search.md\n",
      "  -> Successfully saved 009_Manual_Wiring_of_Search_Components_No_IaC_Provided.md\n",
      "  -> Successfully saved 010_Heterogeneous_Sample_Documents_for_End-to-End_Validation.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 10 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/likhithkanigolla/LLMOps-Platform.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpmipjhmm5...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: agent-Service\\agent.py\n",
      "  - Reading: controller-Service\\controller.py\n",
      "  - Reading: frontend\\app-test.py\n",
      "  - Reading: frontend\\app.py\n",
      "  - Reading: vm-service\\agent.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpmipjhmm5...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately identifies the microservices architecture, correctly deduces the role of each service based on the file and directory names, and correctly identifies the technology stack (Python, Flask, Kafka, Docker, Vagrant) present in the repository.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a high-quality and accurate representation of the architecture described in the summary. They successfully identify and document the six most critical architectural decisions: the microservices pattern, the use of Kafka for asynchronous metrics, the centralized metrics-driven scheduler, dynamic service discovery, decentralized SQLite persistence, and the choice of Vagrant/scripts for automation. Each ADR's 'Context', 'Decision', and 'Consequences' sections are logically sound and directly supported by the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\likhithkanigolla_LLMOps-Platform\\dir3'\n",
      "  -> Successfully saved 001_Microservices_Architecture.md\n",
      "  -> Successfully saved 002_Asynchronous_Metrics_Collection_via_Message_Bus.md\n",
      "  -> Successfully saved 003_Centralized_Metrics-Driven_Workload_Scheduling.md\n",
      "  -> Successfully saved 004_Dynamic_Service_Discovery.md\n",
      "  -> Successfully saved 005_Decentralized_Persistence_with_SQLite.md\n",
      "  -> Successfully saved 006_Infrastructure_Automation_via_Scripting_and_Vagrant.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/likhithkanigolla/LLMOps-Platform.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmppcv7bya2...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: agent-Service\\agent.py\n",
      "  - Reading: controller-Service\\controller.py\n",
      "  - Reading: frontend\\app-test.py\n",
      "  - Reading: frontend\\app.py\n",
      "  - Reading: vm-service\\agent.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmppcv7bya2...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary makes several unverified, specific claims that are not supported by the provided file structure (e.g., CSRF protection, role-based access, Kafka-based metrics pipeline with producer/consumer threads, Caddy integration, thread-safe container registries, and concrete deployment orchestration logic).\n",
      "\n",
      "FEEDBACK: Revise the summary to stick to capabilities that are evidenced by filenames and structure:\n",
      "- Frontend: Describe it as a Flask app with templates and a users.db present; avoid claiming CSRF, roles, or session policies unless confirmed by code.\n",
      "- Service Registry and Model Registry: Note their presence (registry.py, model-registry.py) and SQLite DBs; avoid detailing specific endpoints or behaviors not visible.\n",
      "- Controller-Service: Mention Kafka docker-compose and run_kafka.py exist; donâ€™t assert a metrics consumer/health-based placement logic without code confirmation.\n",
      "- Agent-Service and vm-service: Indicate Flask agent(s) exist and vm-service includes Vagrant; donâ€™t claim Kafka producers, Docker lifecycle management, or thread-safe registries without evidence.\n",
      "- Deployer-Service, API Gateway, Reverse Proxy: Acknowledge their server.py files exist; avoid asserting exact roles or integration patterns.\n",
      "- Infrastructure scripts: Accurately note bootstrap scripts for agents, controller, model registry, frontend, VMs, and NFS.\n",
      "- Remove speculative items like Caddy integration and service-to-service auth/security details unless found in code or README.\n",
      "Focus on verifiable architecture (multiple Python/Flask services, per-service requirements, SQLite usage, Kafka setup scripts, VM/NFS tooling) and qualify anything else as uncertain or omit it.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: agent-Service\\agent.py\n",
      "  - Reading: controller-Service\\controller.py\n",
      "  - Reading: frontend\\app-test.py\n",
      "  - Reading: frontend\\app.py\n",
      "  - Reading: vm-service\\agent.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmppcv7bya2...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repositoryâ€™s multi-service Python layout, identifies each service and its entrypoints, notes the SQLite databases, Kafka tooling, Vagrant/NFS scripts, and appropriately caveats unconfirmed runtime details.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summaryâ€™s evidence: Python/Flask-style microservices with per-service requirements, SQLite-backed persistence, a bespoke service registry, Kafka tooling near the controller, Vagrant-based VM workflows, NFS boot scripts, distinct API Gateway and Reverse Proxy services, control-plane vs. agents split, shell-based bootstrapping, frontend-managed auth with a local users.db, and non-containerized services. The Context/Decision/Consequences sections are plausible and balanced for this codebase.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\likhithkanigolla_LLMOps-Platform\\dir4'\n",
      "  -> Successfully saved 001_Uniform_PythonFlask_microservices_architecture.md\n",
      "  -> Successfully saved 002_Local_SQLite_for_persistence_per_service.md\n",
      "  -> Successfully saved 003_Custom_in-repo_Service_Registry_instead_of_a_standard_solution.md\n",
      "  -> Successfully saved 004_Event-driven_integration_via_Kafka_for_controller_workflows.md\n",
      "  -> Successfully saved 005_VM-based_deployment_and_testing_with_Vagrant.md\n",
      "  -> Successfully saved 006_Shared_storage_via_NFS_for_modelartifact_distribution.md\n",
      "  -> Successfully saved 007_Layered_edge_with_API_Gateway_and_Reverse_Proxy.md\n",
      "  -> Successfully saved 008_Control_plane_controllerdeployer_separated_from_agent_execution.md\n",
      "  -> Successfully saved 009_Operational_bootstrap_via_shell_scripts_instead_of_an_orchestrator.md\n",
      "  -> Successfully saved 010_Frontend-managed_authentication_with_local_user_store.md\n",
      "  -> Successfully saved 011_Run_services_directly_on_hostsVMs_rather_than_containerizing_all_components.md\n",
      "  -> Successfully saved 012_Per-service_dependency_isolation_via_requirements.txt.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/likhithkanigolla/CAPS-IIITH.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpflwic2tn...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: llmbased\\metrics-all.md\n",
      "  - Reading: BASE\\generator.py\n",
      "  - Reading: llmbased\\generator\\model_generator.py\n",
      "  - Reading: llmbased\\web\\web_generator.py\n",
      "  - Reading: generator\\file_generators.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpflwic2tn...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary provides an exceptionally accurate and insightful high-level overview of the repository. It correctly identifies the core purpose of the project: comparing a traditional, parser-based code generation workflow (`generator/`, `BASE/`) with a modern, LLM-based one (`llmbased/`). The summary accurately maps specific files and directories (e.g., `llmbased/web/web_generator.py`, `metamodel-saml.puml`, `SAML-SAMPLE/`) to their respective functions within this dual-path architecture.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The provided ADRs are excellent and accurately reflect the key architectural decisions outlined in the repository summary. Each ADR is well-justified and directly supported by specific details in the summary, including the dual-path comparative architecture (ADR-001), the use of an intermediate JSON representation (ADR-002), the selection of PyDEVS (ADR-003), the creation of the custom SAML DSL (ADR-004), the integration of a metrics framework (ADR-005), and the generation of web-based visualizations (ADR-006). The set comprehensively covers the project's core design pillars.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\likhithkanigolla_CAPS-IIITH\\dir3'\n",
      "  -> Successfully saved 001_Dual-Path_Architecture_for_Comparative_Analysis.md\n",
      "  -> Successfully saved 002_Use_of_an_Intermediate_Representation_JSON_in_the_LLM-Based_Workflow.md\n",
      "  -> Successfully saved 003_Adoption_of_PyDEVS_for_Discrete-Event_Simulation.md\n",
      "  -> Successfully saved 004_Definition_of_a_Custom_Domain-Specific_Language_SAML.md\n",
      "  -> Successfully saved 005_Integration_of_a_Comprehensive_Metrics_Collection_Framework.md\n",
      "  -> Successfully saved 006_Automated_Generation_of_Dynamic_Web-Based_Visualizations.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/likhithkanigolla/CAPS-IIITH.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpewzjpgje...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: llmbased\\metrics-all.md\n",
      "  - Reading: BASE\\generator.py\n",
      "  - Reading: llmbased\\generator\\model_generator.py\n",
      "  - Reading: llmbased\\web\\web_generator.py\n",
      "  - Reading: generator\\file_generators.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpewzjpgje...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary over-asserts several specifics not clearly supported by the repository contents.\n",
      "FEEDBACK:\n",
      "- Remove provider-specific claims (Gemini). Refer to a generic â€œLLM-based pipelineâ€ unless the requirements explicitly show Gemini/Google Generative AI.\n",
      "- Drop â€œHWMLâ€ unless you can cite files or docs in the repo that reference it.\n",
      "- Soften or verify specifics about DEVS internals (e.g., â€œAtomicDEVS,â€ detailed time-advance semantics) and sensor behavior (â€œm2m:cinâ€ broadcasting to all output ports). State that oneM2M interfaces exist and PyDEVS-like code is generated, unless you can confirm these exact behaviors from the code.\n",
      "- Keep the rest (two pipelines, CAPSSAML input, web generator from model.json, metrics collection, sample outputs, scripts) as these are well supported by the structure.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: llmbased\\metrics-all.md\n",
      "  - Reading: BASE\\generator.py\n",
      "  - Reading: llmbased\\generator\\model_generator.py\n",
      "  - Reading: llmbased\\web\\web_generator.py\n",
      "  - Reading: generator\\file_generators.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpewzjpgje...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repositoryâ€™s structure and purpose, capturing the two pipelines (procedural and LLM-based), key directories/files, generated artifacts (Python code, model.json, web assets), and metrics tooling. Minor path nuances (e.g., NOTES under llmbased) donâ€™t affect the overall correctness.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary across all key choices: dual pipelines (baseline and LLM), CAPSSAML-to-DEVS mapping, DEVS-style generation without strict PyDEVS coupling, use of model.json as an IR, lightweight web visualization, integrated metrics, template-driven generation, script-based orchestration, optional oneM2M examples, modular repo layout, UML/sequence documentation, and explicit non-committal DEVS semantics. The Context, Decision, and Consequences sections are plausible and supported by the summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\likhithkanigolla_CAPS-IIITH\\dir4'\n",
      "  -> Successfully saved 001_Dual-pipeline_architecture_baseline__LLM.md\n",
      "  -> Successfully saved 002_CAPSSAML-to-DEVS_transformation_as_core_mapping.md\n",
      "  -> Successfully saved 003_DEVS-style_generation_without_strict_PyDEVS_coupling.md\n",
      "  -> Successfully saved 004_Intermediate_representation_via_model.json.md\n",
      "  -> Successfully saved 005_Lightweight_web_visualization_generated_from_IR.md\n",
      "  -> Successfully saved 006_Metrics-first_instrumentation_for_generation_and_simulation.md\n",
      "  -> Successfully saved 007_Template-driven_code_generation.md\n",
      "  -> Successfully saved 008_Script-oriented_orchestration_over_packaged_CLI.md\n",
      "  -> Successfully saved 009_Optional_oneM2M_interface_modules_in_examples.md\n",
      "  -> Successfully saved 010_Repository_modularization_by_concern.md\n",
      "  -> Successfully saved 011_Documentation_via_UML_artifacts_and_recorded_sequences.md\n",
      "  -> Successfully saved 012_Explicitly_non-committal_DEVS_semantics.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Repository URL\n",
    "https://github.com/karthikv1392/cs6401_se.git\"\n",
    "https://github.com/sa4s-serc/HarmonE\n",
    "https://github.com/srini1978/carbonQL\n",
    "https://github.com/srini1978/AzureCognitiveSearchDemo\n",
    "https://github.com/likhithkanigolla/LLMOps-Platform\n",
    "https://github.com/likhithkanigolla/CAPS-IIITH\n",
    "https://github.com/sa4s-serc/EdgeMLBalancer\n",
    "https://github.com/sa4s-serc/switch\n",
    "https://github.com/sa4s-serc/EcoMLS\n",
    "https://github.com/sa4s-serc/AdaMLS\n",
    "https://github.com/akhiha/juice-shop\n",
    "https://gitlab.com/20a_akhila/amazon-clone\n",
    "https://gitlab.com/20a_akhila/movie-database\n",
    "https://gitlab.com/20a_akhila/silly_story_generator\n",
    "\"\"\"\n",
    "\n",
    "repos = [\"https://github.com/sa4s-serc/EdgeMLBalancer\",\n",
    "         \"https://github.com/sa4s-serc/switch\",\n",
    "         \"https://github.com/sa4s-serc/EcoMLS\",\n",
    "         \"https://github.com/sa4s-serc/AdaMLS\",\n",
    "         \"https://github.com/akhiha/juice-shop\",\n",
    "         \"https://gitlab.com/20a_akhila/amazon-clone\",\n",
    "         \"https://gitlab.com/20a_akhila/movie-database\",\n",
    "         \"https://gitlab.com/20a_akhila/silly_story_generator\"]\n",
    "\n",
    "for repo_url_to_process in repos:\n",
    "    generate_adrs(repo_url_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c18234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
