{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LAB\\ADR\\AgenticAdr\n"
     ]
    }
   ],
   "source": [
    "cd D:\\LAB\\ADR\\AgenticAdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a47523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.AdrAgents import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72638812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adrs(repo_url_to_process):\n",
    "    output_directory_for_adrs = 'Generated_ADRs/' + repo_url_to_process[19:].removesuffix('.git').replace('/', '_')\n",
    "\n",
    "    output_directory_for_adrs_gimini = output_directory_for_adrs + '/dir3'\n",
    "    model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gimini = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gimini.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gimini,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gimini. {len(final_adrs)} ADRs were generated and saved.\")\n",
    "\n",
    "    output_directory_for_adrs_gpt = output_directory_for_adrs + '/dir4'\n",
    "    model_name = \"gpt-5\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gpt = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gpt.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gpt,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gpt. {len(final_adrs)} ADRs were generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e74aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sa4s-serc/HarmonE.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpu5q7_hf_...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: README.md\n",
      "  - Reading: mape\\analyse.py\n",
      "  - Reading: tools\\train_models.py\n",
      "  - Reading: retrain.py\n",
      "  - Reading: inference.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpu5q7_hf_...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately describes the repository's structure and purpose, correctly identifying the MAPE-K (Monitor-Analyze-Plan-Execute over Knowledge base) architecture, which is clearly reflected in the `mape/` and `knowledge/` directory structures and their constituent files.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 7 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The provided ADRs are an excellent and accurate representation of the architectural decisions described in the repository summary. Each ADR is well-defined, logical, and directly substantiated by specific details in the summary. They correctly identify the most critical decisions: the choice of the MAPE-K pattern, the focus on energy consumption, the file-based knowledge store, the dynamic model switching strategy, data versioning, the use of KL-divergence for analysis, and the integration of pyRAPL for monitoring.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sa4s-serc_HarmonE\\dir3'\n",
      "  -> Successfully saved 001_MAPE-K_Control_Loop_for_Self-Adaptation.md\n",
      "  -> Successfully saved 002_Prioritizing_Energy_Consumption_as_a_First-Class_Metric.md\n",
      "  -> Successfully saved 003_File-Based_Knowledge_Base_for_State_Management.md\n",
      "  -> Successfully saved 004_Dynamic_Model_Switching_as_the_Primary_Adaptation_Strategy.md\n",
      "  -> Successfully saved 005_Strict_Model_and_Data_Versioning_for_Reproducibility.md\n",
      "  -> Successfully saved 006_Kullback-Leibler_KL_Divergence_for_Model_Candidate_Selection.md\n",
      "  -> Successfully saved 007_Adoption_of_pyRAPL_for_Energy_Monitoring.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 7 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sa4s-serc/HarmonE.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpntm33lqe...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: README.md\n",
      "  - Reading: mape\\analyse.py\n",
      "  - Reading: tools\\train_models.py\n",
      "  - Reading: retrain.py\n",
      "  - Reading: inference.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpntm33lqe...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts many specifics that are not supported by the provided repository context.\n",
      "\n",
      "FEEDBACK: Revise the summary to stick to what is evidenced by the repository:\n",
      "- Confirm the MAPE-K structure based on mape/analyse.py, monitor.py, plan.py, execute.py and mape/manage.py.\n",
      "- Describe the file-based knowledge base using the existing knowledge files (model.csv, drift.csv, predictions.csv, thresholds.json, mape_info.json, mape_log.csv).\n",
      "- Mention available scripts: inference.py, retrain.py, and tools/ (induce_drift.py, store_pems.py, load_test_models.py, train_models.py), and configuration via approach.conf and set_approach.sh.\n",
      "- Remove or qualify unverified claims, including:\n",
      "  - Energy measurement via pyRAPL and per-inference latency logging (not evidenced).\n",
      "  - Specific algorithms/metrics like KL divergence, cooldown logic, or threshold adaptation (not evidenced).\n",
      "  - Specific model families (LSTM, SVR, Ridge) and PyTorch usage (not evidenced).\n",
      "  - Versioning scheme and directories like models/ or versionedMR/... (not present).\n",
      "  - Dependency details (e.g., pymongo, PyTorch) unless confirmed in requirements.txt.\n",
      "Focus on a high-level, evidence-backed summary of a Python MAPE-K framework with file-based knowledge storage and utilities for drift induction and PEMS data handling.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: README.md\n",
      "  - Reading: mape\\analyse.py\n",
      "  - Reading: tools\\train_models.py\n",
      "  - Reading: retrain.py\n",
      "  - Reading: inference.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpntm33lqe...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary makes unverified claims about the repository name and exact dependencies.\n",
      "FEEDBACK: Remove the specific repo name â€œHarmonEâ€ unless it appears in README.md, and avoid listing exact packages from requirements.txt since their contents werenâ€™t provided. Instead, state that requirements.txt defines dependencies. Optionally soften assertions like â€œPEMS dataset handlingâ€ to â€œlikely handles PEMS dataâ€ based on the filename. Otherwise, keep the MAPE-K structure, file-backed knowledge, scripts, and tooling descriptions as they align with the directory structure.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 3 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: README.md\n",
      "  - Reading: mape\\analyse.py\n",
      "  - Reading: tools\\train_models.py\n",
      "  - Reading: retrain.py\n",
      "  - Reading: inference.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpntm33lqe...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes several specific claims that are not verifiable from the provided repository context.\n",
      "\n",
      "FEEDBACK: Trim speculative details and stick to what the file structure supports. Specifically:\n",
      "- Do not assert the project name (â€œHarmonEâ€), pyRAPL usage, PyTorch/LSTM or SVM models, KL divergence, dynamic energy thresholds, or recovery-cycle mechanisms unless confirmed in README, requirements.txt, or code.\n",
      "- Describe the MAPE-K structure at a high level (monitor/analyse/plan/execute/manage modules exist) and the file-backed knowledge store (thresholds.json, model.csv, predictions.csv, drift.csv, mape_info.json, mape_log.csv).\n",
      "- Note the presence of inference.py and retrain.py without detailing unverified internals (e.g., energy measurement library).\n",
      "- Mention tools for training, inducing drift, loading test models, and data preparation (PEMS reference is plausible but qualify as â€œtraffic data utilitiesâ€ unless README confirms PEMS).\n",
      "- Keep configuration/scripts (approach.conf, set_approach.sh, cleanup.sh) and typical workflow high-level without unverified implementation specifics.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align closely with the repository summary and capture the key architectural decisions: explicit MAPE-K decomposition, file-backed knowledge store, dynamic energy thresholds with recovery cycles, filesystem model registry with rollback, knowledge-driven streaming inference, CPU energy measurement via pyRAPL, heterogeneous model support (PyTorch LSTM and classical models), drift-aware candidate selection, selective retraining with versioning, time-series preprocessing, externalized configuration, and comprehensive logging. Context, decisions, and consequences are plausible and grounded in the described code and workflows.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sa4s-serc_HarmonE\\dir4'\n",
      "  -> Successfully saved 001_Explicit_MAPE-K_feedback-loop_architecture.md\n",
      "  -> Successfully saved 002_Persistent_file-backed_Knowledge_store.md\n",
      "  -> Successfully saved 003_Energy-aware_adaptation_using_dynamic_thresholds_and_recovery_cycles.md\n",
      "  -> Successfully saved 004_Filesystem-based_model_registry_with_versioned_subfolders_and_rollback.md\n",
      "  -> Successfully saved 005_Knowledge-driven_streaming_inference.md\n",
      "  -> Successfully saved 006_CPU_energy_measurement_via_pyRAPL.md\n",
      "  -> Successfully saved 007_Heterogeneous_model_support_PyTorch_LSTM_and_classical_regressors.md\n",
      "  -> Successfully saved 008_Drift-aware_candidate_selection_using_distribution_similarity_KL_divergence.md\n",
      "  -> Successfully saved 009_Selective_retraining_on_drift_data_with_version_registration.md\n",
      "  -> Successfully saved 010_Time-series_preprocessing_with_sliding_windows_and_minmax_scaling.md\n",
      "  -> Successfully saved 011_Configuration_externalization_via_approach.conf_and_shell_scripts.md\n",
      "  -> Successfully saved 012_Comprehensive_logging_and_traceability_of_adaptation_decisions.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n"
     ]
    }
   ],
   "source": [
    "# repo_url_to_process = \"https://github.com/sa4s-serc/HarmonE.git\"\n",
    "# generate_adrs(repo_url_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Repository URL\n",
    "https://github.com/sa4s-serc/HarmonE\n",
    "https://github.com/srini1978/carbonQL\n",
    "https://github.com/srini1978/AzureCognitiveSearchDemo\n",
    "https://github.com/likhithkanigolla/LLMOps-Platform\n",
    "https://github.com/likhithkanigolla/CAPS-IIITH\n",
    "\"\"\"\n",
    "\n",
    "repos = [\"https://github.com/srini1978/carbonQL.git\",\n",
    "         \"https://github.com/srini1978/AzureCognitiveSearchDemo.git\",\n",
    "         \"https://github.com/likhithkanigolla/LLMOps-Platform.git\",\n",
    "         \"https://github.com/likhithkanigolla/CAPS-IIITH.git\"]\n",
    "\n",
    "for repo_url_to_process in repos:\n",
    "    generate_adrs(repo_url_to_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
